{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e659b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 08:08:33.131066: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-05-31 08:08:33.165782: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-31 08:08:33.165804: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-31 08:08:33.166868: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-31 08:08:33.172282: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 24 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from scipy import ndimage, misc\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import gc\n",
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from numpy.random import default_rng\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "rng = default_rng(42)\n",
    "import glob\n",
    "import seaborn as sns\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "import h5py\n",
    "from keras.callbacks import EarlyStopping\n",
    "#from mlxtend.plotting import plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f8923af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 08:08:35.708739: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 08:08:35.718060: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 08:08:35.718147: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41d10533-9432-4796-adae-b980f5f3eaa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "carpetas = [\"z_cero\",'zvar','fits_inclinated']\n",
    "path = '/project/Data/SAD_CNN/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0bcd14a-8acb-44c7-9f52-abe421f3d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path + carpetas[1] + \"/\" + carpetas[1] + \"_dataset.h5\", 'r') as hdf:\n",
    "    x_train_1 = hdf['x_train'][:].astype(np.float32)\n",
    "    train_labels_1 = hdf['train_labels'][:].astype(int)\n",
    "    x_val_1 = hdf['x_val'][:].astype(np.float32)\n",
    "    val_labels_1 = hdf['val_labels'][:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3106f19f-ceb3-4a2b-ae7d-2fa271ac443f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(path + carpetas[0] + \"/\" + carpetas[0] + \"_dataset.h5\", 'r') as hdf:\n",
    "    x_train_0 = hdf['x_train'][:].astype(np.float32)\n",
    "    train_labels_0 = hdf['train_labels'][:].astype(int)\n",
    "    x_val_0 = hdf['x_val'][:].astype(np.float32)\n",
    "    val_labels_0 = hdf['val_labels'][:].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3646b108-bab6-4011-8b1a-67220d12e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator()\n",
    "validation_datagen = ImageDataGenerator()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc86764-e5a3-468d-bad6-19faf172dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Abrir el archivo en modo de solo lectura\n",
    "with h5py.File(path + carpetas[2] + \"/\" + carpetas[2] + \"_dataset.h5\", 'r') as hdf:\n",
    "\n",
    "    train_gen = train_datagen.flow(\n",
    "         np.concatenate([x_train_0,x_train_1,hdf['x_train'][:].astype(np.float32)], axis=0),\n",
    "        np.concatenate([train_labels_0,train_labels_1,hdf['train_labels'][:].astype(int)], axis=0),\n",
    "    batch_size=64,shuffle=True\n",
    "    )\n",
    "    \n",
    "    val_gen = validation_datagen.flow(\n",
    "    np.concatenate([x_val_0,x_val_1,hdf['x_val'][:].astype(np.float32)], axis=0),\n",
    "     np.concatenate([val_labels_0,val_labels_1,hdf['val_labels'][:].astype(int)], axis=0),\n",
    "    batch_size=32,shuffle=True\n",
    "    )\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7774d88d-e738-4519-b49e-439615ad29db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 08:15:49.756136: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 08:15:49.756285: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 08:15:49.756382: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 08:15:49.847652: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 08:15:49.847778: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 08:15:49.847883: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-31 08:15:49.848014: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5383 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x73a07023ffd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = keras.applications.Xception(\n",
    "weights='imagenet',  # Load weights pre-trained on ImageNet.\n",
    "input_shape=(300, 300, 3),\n",
    "include_top=False)\n",
    "base_model.trainable = False\n",
    "inputs = keras.Input(shape=(300, 300, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "# Convert features of shape `base_model.output_shape[1:]` to vectors\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "# A Dense classifier with a single unit (binary classification)\n",
    "outputs = keras.layers.Dense(1,activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
    "          loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "          metrics=[keras.metrics.BinaryAccuracy()])\n",
    "\n",
    "model.load_weights(f'labels/{carpetas[1]}/checkpoints_transfer/my_checkpoint_transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec7fcf4f-b9ac-4e4b-acd3-fb40f25e5644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 08:16:16.566617: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/237 [..............................] - ETA: 25:03 - loss: 0.2704 - binary_accuracy: 0.8750"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-31 08:16:21.154320: I external/local_xla/xla/service/service.cc:168] XLA service 0x739b939b40e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-05-31 08:16:21.154340: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4060 Laptop GPU, Compute Capability 8.9\n",
      "2024-05-31 08:16:21.165801: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1717143381.240755  150281 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "237/237 [==============================] - 86s 336ms/step - loss: 0.3633 - binary_accuracy: 0.8522 - val_loss: 0.3076 - val_binary_accuracy: 0.8647\n",
      "Epoch 2/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.3331 - binary_accuracy: 0.8594 - val_loss: 0.2934 - val_binary_accuracy: 0.8738\n",
      "Epoch 3/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.3213 - binary_accuracy: 0.8615 - val_loss: 0.2866 - val_binary_accuracy: 0.8752\n",
      "Epoch 4/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.3139 - binary_accuracy: 0.8656 - val_loss: 0.2822 - val_binary_accuracy: 0.8747\n",
      "Epoch 5/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.3084 - binary_accuracy: 0.8683 - val_loss: 0.2792 - val_binary_accuracy: 0.8779\n",
      "Epoch 6/200\n",
      "237/237 [==============================] - 73s 307ms/step - loss: 0.3041 - binary_accuracy: 0.8703 - val_loss: 0.2770 - val_binary_accuracy: 0.8770\n",
      "Epoch 7/200\n",
      "237/237 [==============================] - 73s 308ms/step - loss: 0.3007 - binary_accuracy: 0.8724 - val_loss: 0.2751 - val_binary_accuracy: 0.8784\n",
      "Epoch 8/200\n",
      "237/237 [==============================] - 73s 310ms/step - loss: 0.2976 - binary_accuracy: 0.8734 - val_loss: 0.2729 - val_binary_accuracy: 0.8811\n",
      "Epoch 9/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2950 - binary_accuracy: 0.8754 - val_loss: 0.2724 - val_binary_accuracy: 0.8779\n",
      "Epoch 10/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2927 - binary_accuracy: 0.8766 - val_loss: 0.2707 - val_binary_accuracy: 0.8820\n",
      "Epoch 11/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2907 - binary_accuracy: 0.8768 - val_loss: 0.2700 - val_binary_accuracy: 0.8811\n",
      "Epoch 12/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2890 - binary_accuracy: 0.8765 - val_loss: 0.2690 - val_binary_accuracy: 0.8820\n",
      "Epoch 13/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2872 - binary_accuracy: 0.8784 - val_loss: 0.2679 - val_binary_accuracy: 0.8820\n",
      "Epoch 14/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2857 - binary_accuracy: 0.8782 - val_loss: 0.2680 - val_binary_accuracy: 0.8811\n",
      "Epoch 15/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2843 - binary_accuracy: 0.8794 - val_loss: 0.2665 - val_binary_accuracy: 0.8848\n",
      "Epoch 16/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2828 - binary_accuracy: 0.8807 - val_loss: 0.2665 - val_binary_accuracy: 0.8871\n",
      "Epoch 17/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2818 - binary_accuracy: 0.8804 - val_loss: 0.2659 - val_binary_accuracy: 0.8834\n",
      "Epoch 18/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2806 - binary_accuracy: 0.8823 - val_loss: 0.2653 - val_binary_accuracy: 0.8829\n",
      "Epoch 19/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2795 - binary_accuracy: 0.8830 - val_loss: 0.2645 - val_binary_accuracy: 0.8852\n",
      "Epoch 20/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2784 - binary_accuracy: 0.8831 - val_loss: 0.2640 - val_binary_accuracy: 0.8843\n",
      "Epoch 21/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2774 - binary_accuracy: 0.8845 - val_loss: 0.2635 - val_binary_accuracy: 0.8866\n",
      "Epoch 22/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2765 - binary_accuracy: 0.8846 - val_loss: 0.2638 - val_binary_accuracy: 0.8848\n",
      "Epoch 23/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2757 - binary_accuracy: 0.8852 - val_loss: 0.2627 - val_binary_accuracy: 0.8852\n",
      "Epoch 24/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2748 - binary_accuracy: 0.8867 - val_loss: 0.2626 - val_binary_accuracy: 0.8871\n",
      "Epoch 25/200\n",
      "237/237 [==============================] - 73s 307ms/step - loss: 0.2741 - binary_accuracy: 0.8869 - val_loss: 0.2624 - val_binary_accuracy: 0.8852\n",
      "Epoch 26/200\n",
      "237/237 [==============================] - 74s 312ms/step - loss: 0.2732 - binary_accuracy: 0.8868 - val_loss: 0.2618 - val_binary_accuracy: 0.8857\n",
      "Epoch 27/200\n",
      "237/237 [==============================] - 74s 311ms/step - loss: 0.2724 - binary_accuracy: 0.8872 - val_loss: 0.2619 - val_binary_accuracy: 0.8852\n",
      "Epoch 28/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2718 - binary_accuracy: 0.8877 - val_loss: 0.2613 - val_binary_accuracy: 0.8852\n",
      "Epoch 29/200\n",
      "237/237 [==============================] - 73s 310ms/step - loss: 0.2710 - binary_accuracy: 0.8881 - val_loss: 0.2610 - val_binary_accuracy: 0.8848\n",
      "Epoch 30/200\n",
      "237/237 [==============================] - 74s 312ms/step - loss: 0.2703 - binary_accuracy: 0.8889 - val_loss: 0.2605 - val_binary_accuracy: 0.8848\n",
      "Epoch 31/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2694 - binary_accuracy: 0.8890 - val_loss: 0.2618 - val_binary_accuracy: 0.8834\n",
      "Epoch 32/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2691 - binary_accuracy: 0.8892 - val_loss: 0.2604 - val_binary_accuracy: 0.8848\n",
      "Epoch 33/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2683 - binary_accuracy: 0.8904 - val_loss: 0.2601 - val_binary_accuracy: 0.8875\n",
      "Epoch 34/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2678 - binary_accuracy: 0.8903 - val_loss: 0.2603 - val_binary_accuracy: 0.8893\n",
      "Epoch 35/200\n",
      "237/237 [==============================] - 74s 314ms/step - loss: 0.2672 - binary_accuracy: 0.8898 - val_loss: 0.2603 - val_binary_accuracy: 0.8848\n",
      "Epoch 36/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2666 - binary_accuracy: 0.8908 - val_loss: 0.2596 - val_binary_accuracy: 0.8884\n",
      "Epoch 37/200\n",
      "237/237 [==============================] - 74s 310ms/step - loss: 0.2661 - binary_accuracy: 0.8904 - val_loss: 0.2597 - val_binary_accuracy: 0.8861\n",
      "Epoch 38/200\n",
      "237/237 [==============================] - 73s 307ms/step - loss: 0.2654 - binary_accuracy: 0.8912 - val_loss: 0.2594 - val_binary_accuracy: 0.8848\n",
      "Epoch 39/200\n",
      "237/237 [==============================] - 73s 308ms/step - loss: 0.2649 - binary_accuracy: 0.8918 - val_loss: 0.2588 - val_binary_accuracy: 0.8880\n",
      "Epoch 40/200\n",
      "237/237 [==============================] - 73s 308ms/step - loss: 0.2646 - binary_accuracy: 0.8906 - val_loss: 0.2588 - val_binary_accuracy: 0.8903\n",
      "Epoch 41/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2640 - binary_accuracy: 0.8918 - val_loss: 0.2582 - val_binary_accuracy: 0.8875\n",
      "Epoch 42/200\n",
      "237/237 [==============================] - 74s 311ms/step - loss: 0.2636 - binary_accuracy: 0.8910 - val_loss: 0.2580 - val_binary_accuracy: 0.8893\n",
      "Epoch 43/200\n",
      "237/237 [==============================] - 74s 310ms/step - loss: 0.2631 - binary_accuracy: 0.8917 - val_loss: 0.2581 - val_binary_accuracy: 0.8884\n",
      "Epoch 44/200\n",
      "237/237 [==============================] - 73s 308ms/step - loss: 0.2626 - binary_accuracy: 0.8919 - val_loss: 0.2573 - val_binary_accuracy: 0.8889\n",
      "Epoch 45/200\n",
      "237/237 [==============================] - 73s 307ms/step - loss: 0.2621 - binary_accuracy: 0.8927 - val_loss: 0.2573 - val_binary_accuracy: 0.8889\n",
      "Epoch 46/200\n",
      "237/237 [==============================] - 74s 313ms/step - loss: 0.2616 - binary_accuracy: 0.8935 - val_loss: 0.2579 - val_binary_accuracy: 0.8889\n",
      "Epoch 47/200\n",
      "237/237 [==============================] - 74s 311ms/step - loss: 0.2613 - binary_accuracy: 0.8931 - val_loss: 0.2568 - val_binary_accuracy: 0.8889\n",
      "Epoch 48/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2608 - binary_accuracy: 0.8939 - val_loss: 0.2571 - val_binary_accuracy: 0.8907\n",
      "Epoch 49/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2604 - binary_accuracy: 0.8933 - val_loss: 0.2573 - val_binary_accuracy: 0.8889\n",
      "Epoch 50/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2600 - binary_accuracy: 0.8924 - val_loss: 0.2567 - val_binary_accuracy: 0.8903\n",
      "Epoch 51/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2596 - binary_accuracy: 0.8933 - val_loss: 0.2566 - val_binary_accuracy: 0.8898\n",
      "Epoch 52/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2591 - binary_accuracy: 0.8934 - val_loss: 0.2561 - val_binary_accuracy: 0.8898\n",
      "Epoch 53/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2588 - binary_accuracy: 0.8941 - val_loss: 0.2561 - val_binary_accuracy: 0.8898\n",
      "Epoch 54/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2583 - binary_accuracy: 0.8939 - val_loss: 0.2557 - val_binary_accuracy: 0.8903\n",
      "Epoch 55/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2579 - binary_accuracy: 0.8941 - val_loss: 0.2558 - val_binary_accuracy: 0.8889\n",
      "Epoch 56/200\n",
      "237/237 [==============================] - 73s 308ms/step - loss: 0.2576 - binary_accuracy: 0.8944 - val_loss: 0.2556 - val_binary_accuracy: 0.8903\n",
      "Epoch 57/200\n",
      "237/237 [==============================] - 74s 311ms/step - loss: 0.2572 - binary_accuracy: 0.8949 - val_loss: 0.2557 - val_binary_accuracy: 0.8903\n",
      "Epoch 58/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2566 - binary_accuracy: 0.8947 - val_loss: 0.2562 - val_binary_accuracy: 0.8930\n",
      "Epoch 59/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2565 - binary_accuracy: 0.8951 - val_loss: 0.2555 - val_binary_accuracy: 0.8903\n",
      "Epoch 60/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2561 - binary_accuracy: 0.8954 - val_loss: 0.2558 - val_binary_accuracy: 0.8898\n",
      "Epoch 61/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2558 - binary_accuracy: 0.8956 - val_loss: 0.2553 - val_binary_accuracy: 0.8907\n",
      "Epoch 62/200\n",
      "237/237 [==============================] - 73s 307ms/step - loss: 0.2554 - binary_accuracy: 0.8951 - val_loss: 0.2545 - val_binary_accuracy: 0.8903\n",
      "Epoch 63/200\n",
      "237/237 [==============================] - 73s 310ms/step - loss: 0.2549 - binary_accuracy: 0.8958 - val_loss: 0.2542 - val_binary_accuracy: 0.8903\n",
      "Epoch 64/200\n",
      "237/237 [==============================] - 73s 308ms/step - loss: 0.2548 - binary_accuracy: 0.8956 - val_loss: 0.2546 - val_binary_accuracy: 0.8903\n",
      "Epoch 65/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2543 - binary_accuracy: 0.8962 - val_loss: 0.2540 - val_binary_accuracy: 0.8907\n",
      "Epoch 66/200\n",
      "237/237 [==============================] - 73s 308ms/step - loss: 0.2540 - binary_accuracy: 0.8958 - val_loss: 0.2538 - val_binary_accuracy: 0.8916\n",
      "Epoch 67/200\n",
      "237/237 [==============================] - 74s 311ms/step - loss: 0.2537 - binary_accuracy: 0.8960 - val_loss: 0.2540 - val_binary_accuracy: 0.8916\n",
      "Epoch 68/200\n",
      "237/237 [==============================] - 74s 311ms/step - loss: 0.2534 - binary_accuracy: 0.8960 - val_loss: 0.2538 - val_binary_accuracy: 0.8903\n",
      "Epoch 69/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2530 - binary_accuracy: 0.8964 - val_loss: 0.2537 - val_binary_accuracy: 0.8889\n",
      "Epoch 70/200\n",
      "237/237 [==============================] - 75s 315ms/step - loss: 0.2527 - binary_accuracy: 0.8964 - val_loss: 0.2533 - val_binary_accuracy: 0.8925\n",
      "Epoch 71/200\n",
      "237/237 [==============================] - 73s 310ms/step - loss: 0.2523 - binary_accuracy: 0.8970 - val_loss: 0.2538 - val_binary_accuracy: 0.8921\n",
      "Epoch 72/200\n",
      "237/237 [==============================] - 73s 307ms/step - loss: 0.2521 - binary_accuracy: 0.8971 - val_loss: 0.2534 - val_binary_accuracy: 0.8898\n",
      "Epoch 73/200\n",
      "237/237 [==============================] - 74s 310ms/step - loss: 0.2519 - binary_accuracy: 0.8966 - val_loss: 0.2530 - val_binary_accuracy: 0.8921\n",
      "Epoch 74/200\n",
      "237/237 [==============================] - 74s 312ms/step - loss: 0.2515 - binary_accuracy: 0.8974 - val_loss: 0.2528 - val_binary_accuracy: 0.8916\n",
      "Epoch 75/200\n",
      "237/237 [==============================] - 72s 306ms/step - loss: 0.2512 - binary_accuracy: 0.8978 - val_loss: 0.2529 - val_binary_accuracy: 0.8944\n",
      "Epoch 76/200\n",
      "237/237 [==============================] - 76s 319ms/step - loss: 0.2509 - binary_accuracy: 0.8974 - val_loss: 0.2527 - val_binary_accuracy: 0.8921\n",
      "Epoch 77/200\n",
      "237/237 [==============================] - 74s 313ms/step - loss: 0.2506 - binary_accuracy: 0.8972 - val_loss: 0.2522 - val_binary_accuracy: 0.8916\n",
      "Epoch 78/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2503 - binary_accuracy: 0.8972 - val_loss: 0.2529 - val_binary_accuracy: 0.8907\n",
      "Epoch 79/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2500 - binary_accuracy: 0.8974 - val_loss: 0.2522 - val_binary_accuracy: 0.8925\n",
      "Epoch 80/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2497 - binary_accuracy: 0.8974 - val_loss: 0.2518 - val_binary_accuracy: 0.8921\n",
      "Epoch 81/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2494 - binary_accuracy: 0.8975 - val_loss: 0.2525 - val_binary_accuracy: 0.8907\n",
      "Epoch 82/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2493 - binary_accuracy: 0.8982 - val_loss: 0.2519 - val_binary_accuracy: 0.8912\n",
      "Epoch 83/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2489 - binary_accuracy: 0.8984 - val_loss: 0.2523 - val_binary_accuracy: 0.8907\n",
      "Epoch 84/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2486 - binary_accuracy: 0.8982 - val_loss: 0.2518 - val_binary_accuracy: 0.8912\n",
      "Epoch 85/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2484 - binary_accuracy: 0.8989 - val_loss: 0.2512 - val_binary_accuracy: 0.8912\n",
      "Epoch 86/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2481 - binary_accuracy: 0.8987 - val_loss: 0.2512 - val_binary_accuracy: 0.8925\n",
      "Epoch 87/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2478 - binary_accuracy: 0.8989 - val_loss: 0.2508 - val_binary_accuracy: 0.8916\n",
      "Epoch 88/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2476 - binary_accuracy: 0.8990 - val_loss: 0.2512 - val_binary_accuracy: 0.8925\n",
      "Epoch 89/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2474 - binary_accuracy: 0.8995 - val_loss: 0.2511 - val_binary_accuracy: 0.8912\n",
      "Epoch 90/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2471 - binary_accuracy: 0.8994 - val_loss: 0.2508 - val_binary_accuracy: 0.8925\n",
      "Epoch 91/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2468 - binary_accuracy: 0.9005 - val_loss: 0.2508 - val_binary_accuracy: 0.8912\n",
      "Epoch 92/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2465 - binary_accuracy: 0.8993 - val_loss: 0.2503 - val_binary_accuracy: 0.8921\n",
      "Epoch 93/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2464 - binary_accuracy: 0.9002 - val_loss: 0.2503 - val_binary_accuracy: 0.8921\n",
      "Epoch 94/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2460 - binary_accuracy: 0.8997 - val_loss: 0.2500 - val_binary_accuracy: 0.8925\n",
      "Epoch 95/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2459 - binary_accuracy: 0.9003 - val_loss: 0.2504 - val_binary_accuracy: 0.8921\n",
      "Epoch 96/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2455 - binary_accuracy: 0.8999 - val_loss: 0.2499 - val_binary_accuracy: 0.8916\n",
      "Epoch 97/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2453 - binary_accuracy: 0.9001 - val_loss: 0.2497 - val_binary_accuracy: 0.8930\n",
      "Epoch 98/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2450 - binary_accuracy: 0.9003 - val_loss: 0.2495 - val_binary_accuracy: 0.8916\n",
      "Epoch 99/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2449 - binary_accuracy: 0.9003 - val_loss: 0.2497 - val_binary_accuracy: 0.8921\n",
      "Epoch 100/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2446 - binary_accuracy: 0.9010 - val_loss: 0.2492 - val_binary_accuracy: 0.8916\n",
      "Epoch 101/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2443 - binary_accuracy: 0.9008 - val_loss: 0.2488 - val_binary_accuracy: 0.8916\n",
      "Epoch 102/200\n",
      "237/237 [==============================] - 71s 302ms/step - loss: 0.2441 - binary_accuracy: 0.9008 - val_loss: 0.2489 - val_binary_accuracy: 0.8921\n",
      "Epoch 103/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2439 - binary_accuracy: 0.9011 - val_loss: 0.2489 - val_binary_accuracy: 0.8921\n",
      "Epoch 104/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2436 - binary_accuracy: 0.9013 - val_loss: 0.2486 - val_binary_accuracy: 0.8916\n",
      "Epoch 105/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2435 - binary_accuracy: 0.9014 - val_loss: 0.2487 - val_binary_accuracy: 0.8912\n",
      "Epoch 106/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2432 - binary_accuracy: 0.9006 - val_loss: 0.2489 - val_binary_accuracy: 0.8921\n",
      "Epoch 107/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2429 - binary_accuracy: 0.9015 - val_loss: 0.2487 - val_binary_accuracy: 0.8916\n",
      "Epoch 108/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2428 - binary_accuracy: 0.9010 - val_loss: 0.2483 - val_binary_accuracy: 0.8912\n",
      "Epoch 109/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2426 - binary_accuracy: 0.9020 - val_loss: 0.2485 - val_binary_accuracy: 0.8916\n",
      "Epoch 110/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2423 - binary_accuracy: 0.9022 - val_loss: 0.2485 - val_binary_accuracy: 0.8916\n",
      "Epoch 111/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2421 - binary_accuracy: 0.9018 - val_loss: 0.2484 - val_binary_accuracy: 0.8912\n",
      "Epoch 112/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2419 - binary_accuracy: 0.9018 - val_loss: 0.2479 - val_binary_accuracy: 0.8912\n",
      "Epoch 113/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2416 - binary_accuracy: 0.9013 - val_loss: 0.2482 - val_binary_accuracy: 0.8916\n",
      "Epoch 114/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2415 - binary_accuracy: 0.9015 - val_loss: 0.2477 - val_binary_accuracy: 0.8930\n",
      "Epoch 115/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2412 - binary_accuracy: 0.9018 - val_loss: 0.2476 - val_binary_accuracy: 0.8912\n",
      "Epoch 116/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2409 - binary_accuracy: 0.9016 - val_loss: 0.2478 - val_binary_accuracy: 0.8935\n",
      "Epoch 117/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2409 - binary_accuracy: 0.9024 - val_loss: 0.2472 - val_binary_accuracy: 0.8916\n",
      "Epoch 118/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2406 - binary_accuracy: 0.9027 - val_loss: 0.2475 - val_binary_accuracy: 0.8916\n",
      "Epoch 119/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2404 - binary_accuracy: 0.9022 - val_loss: 0.2473 - val_binary_accuracy: 0.8939\n",
      "Epoch 120/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2401 - binary_accuracy: 0.9030 - val_loss: 0.2473 - val_binary_accuracy: 0.8912\n",
      "Epoch 121/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2400 - binary_accuracy: 0.9026 - val_loss: 0.2474 - val_binary_accuracy: 0.8912\n",
      "Epoch 122/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2398 - binary_accuracy: 0.9027 - val_loss: 0.2470 - val_binary_accuracy: 0.8930\n",
      "Epoch 123/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2394 - binary_accuracy: 0.9037 - val_loss: 0.2469 - val_binary_accuracy: 0.8921\n",
      "Epoch 124/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2393 - binary_accuracy: 0.9033 - val_loss: 0.2470 - val_binary_accuracy: 0.8925\n",
      "Epoch 125/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2391 - binary_accuracy: 0.9030 - val_loss: 0.2465 - val_binary_accuracy: 0.8921\n",
      "Epoch 126/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2390 - binary_accuracy: 0.9035 - val_loss: 0.2464 - val_binary_accuracy: 0.8921\n",
      "Epoch 127/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2387 - binary_accuracy: 0.9035 - val_loss: 0.2467 - val_binary_accuracy: 0.8925\n",
      "Epoch 128/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2385 - binary_accuracy: 0.9040 - val_loss: 0.2472 - val_binary_accuracy: 0.8948\n",
      "Epoch 129/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2384 - binary_accuracy: 0.9034 - val_loss: 0.2466 - val_binary_accuracy: 0.8921\n",
      "Epoch 130/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2381 - binary_accuracy: 0.9041 - val_loss: 0.2470 - val_binary_accuracy: 0.8944\n",
      "Epoch 131/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2381 - binary_accuracy: 0.9032 - val_loss: 0.2466 - val_binary_accuracy: 0.8925\n",
      "Epoch 132/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2379 - binary_accuracy: 0.9046 - val_loss: 0.2465 - val_binary_accuracy: 0.8935\n",
      "Epoch 133/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2375 - binary_accuracy: 0.9035 - val_loss: 0.2464 - val_binary_accuracy: 0.8939\n",
      "Epoch 134/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2374 - binary_accuracy: 0.9033 - val_loss: 0.2462 - val_binary_accuracy: 0.8925\n",
      "Epoch 135/200\n",
      "237/237 [==============================] - 71s 300ms/step - loss: 0.2372 - binary_accuracy: 0.9046 - val_loss: 0.2461 - val_binary_accuracy: 0.8916\n",
      "Epoch 136/200\n",
      "237/237 [==============================] - 71s 299ms/step - loss: 0.2371 - binary_accuracy: 0.9044 - val_loss: 0.2458 - val_binary_accuracy: 0.8916\n",
      "Epoch 137/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2368 - binary_accuracy: 0.9046 - val_loss: 0.2457 - val_binary_accuracy: 0.8939\n",
      "Epoch 138/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2367 - binary_accuracy: 0.9049 - val_loss: 0.2460 - val_binary_accuracy: 0.8935\n",
      "Epoch 139/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2365 - binary_accuracy: 0.9049 - val_loss: 0.2462 - val_binary_accuracy: 0.8944\n",
      "Epoch 140/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2364 - binary_accuracy: 0.9047 - val_loss: 0.2455 - val_binary_accuracy: 0.8935\n",
      "Epoch 141/200\n",
      "237/237 [==============================] - 71s 302ms/step - loss: 0.2361 - binary_accuracy: 0.9044 - val_loss: 0.2452 - val_binary_accuracy: 0.8944\n",
      "Epoch 142/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2360 - binary_accuracy: 0.9045 - val_loss: 0.2448 - val_binary_accuracy: 0.8930\n",
      "Epoch 143/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2357 - binary_accuracy: 0.9046 - val_loss: 0.2449 - val_binary_accuracy: 0.8944\n",
      "Epoch 144/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2356 - binary_accuracy: 0.9047 - val_loss: 0.2445 - val_binary_accuracy: 0.8944\n",
      "Epoch 145/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2354 - binary_accuracy: 0.9056 - val_loss: 0.2454 - val_binary_accuracy: 0.8948\n",
      "Epoch 146/200\n",
      "237/237 [==============================] - 71s 300ms/step - loss: 0.2351 - binary_accuracy: 0.9044 - val_loss: 0.2446 - val_binary_accuracy: 0.8921\n",
      "Epoch 147/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2352 - binary_accuracy: 0.9054 - val_loss: 0.2445 - val_binary_accuracy: 0.8935\n",
      "Epoch 148/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2349 - binary_accuracy: 0.9053 - val_loss: 0.2446 - val_binary_accuracy: 0.8939\n",
      "Epoch 149/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2346 - binary_accuracy: 0.9061 - val_loss: 0.2451 - val_binary_accuracy: 0.8939\n",
      "Epoch 150/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2347 - binary_accuracy: 0.9063 - val_loss: 0.2447 - val_binary_accuracy: 0.8939\n",
      "Epoch 151/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2343 - binary_accuracy: 0.9059 - val_loss: 0.2446 - val_binary_accuracy: 0.8916\n",
      "Epoch 152/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2342 - binary_accuracy: 0.9048 - val_loss: 0.2444 - val_binary_accuracy: 0.8939\n",
      "Epoch 153/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2341 - binary_accuracy: 0.9061 - val_loss: 0.2446 - val_binary_accuracy: 0.8939\n",
      "Epoch 154/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2339 - binary_accuracy: 0.9061 - val_loss: 0.2444 - val_binary_accuracy: 0.8916\n",
      "Epoch 155/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2337 - binary_accuracy: 0.9059 - val_loss: 0.2443 - val_binary_accuracy: 0.8944\n",
      "Epoch 156/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2335 - binary_accuracy: 0.9060 - val_loss: 0.2438 - val_binary_accuracy: 0.8944\n",
      "Epoch 157/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2334 - binary_accuracy: 0.9059 - val_loss: 0.2437 - val_binary_accuracy: 0.8948\n",
      "Epoch 158/200\n",
      "237/237 [==============================] - 71s 300ms/step - loss: 0.2332 - binary_accuracy: 0.9063 - val_loss: 0.2435 - val_binary_accuracy: 0.8948\n",
      "Epoch 159/200\n",
      "237/237 [==============================] - 71s 302ms/step - loss: 0.2331 - binary_accuracy: 0.9064 - val_loss: 0.2436 - val_binary_accuracy: 0.8930\n",
      "Epoch 160/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2329 - binary_accuracy: 0.9061 - val_loss: 0.2433 - val_binary_accuracy: 0.8944\n",
      "Epoch 161/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2327 - binary_accuracy: 0.9069 - val_loss: 0.2437 - val_binary_accuracy: 0.8953\n",
      "Epoch 162/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2325 - binary_accuracy: 0.9054 - val_loss: 0.2432 - val_binary_accuracy: 0.8939\n",
      "Epoch 163/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2324 - binary_accuracy: 0.9065 - val_loss: 0.2432 - val_binary_accuracy: 0.8921\n",
      "Epoch 164/200\n",
      "237/237 [==============================] - 71s 301ms/step - loss: 0.2323 - binary_accuracy: 0.9066 - val_loss: 0.2437 - val_binary_accuracy: 0.8948\n",
      "Epoch 165/200\n",
      "237/237 [==============================] - 72s 302ms/step - loss: 0.2321 - binary_accuracy: 0.9062 - val_loss: 0.2443 - val_binary_accuracy: 0.8935\n",
      "Epoch 166/200\n",
      "237/237 [==============================] - 72s 306ms/step - loss: 0.2319 - binary_accuracy: 0.9070 - val_loss: 0.2434 - val_binary_accuracy: 0.8948\n",
      "Epoch 167/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2316 - binary_accuracy: 0.9065 - val_loss: 0.2438 - val_binary_accuracy: 0.8925\n",
      "Epoch 168/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2317 - binary_accuracy: 0.9075 - val_loss: 0.2429 - val_binary_accuracy: 0.8939\n",
      "Epoch 169/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2315 - binary_accuracy: 0.9067 - val_loss: 0.2429 - val_binary_accuracy: 0.8948\n",
      "Epoch 170/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2313 - binary_accuracy: 0.9074 - val_loss: 0.2426 - val_binary_accuracy: 0.8925\n",
      "Epoch 171/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2311 - binary_accuracy: 0.9071 - val_loss: 0.2429 - val_binary_accuracy: 0.8953\n",
      "Epoch 172/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2311 - binary_accuracy: 0.9068 - val_loss: 0.2432 - val_binary_accuracy: 0.8948\n",
      "Epoch 173/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2308 - binary_accuracy: 0.9069 - val_loss: 0.2425 - val_binary_accuracy: 0.8948\n",
      "Epoch 174/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2307 - binary_accuracy: 0.9077 - val_loss: 0.2425 - val_binary_accuracy: 0.8948\n",
      "Epoch 175/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2305 - binary_accuracy: 0.9073 - val_loss: 0.2427 - val_binary_accuracy: 0.8939\n",
      "Epoch 176/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2304 - binary_accuracy: 0.9072 - val_loss: 0.2423 - val_binary_accuracy: 0.8948\n",
      "Epoch 177/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2302 - binary_accuracy: 0.9080 - val_loss: 0.2425 - val_binary_accuracy: 0.8953\n",
      "Epoch 178/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2301 - binary_accuracy: 0.9076 - val_loss: 0.2419 - val_binary_accuracy: 0.8944\n",
      "Epoch 179/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2300 - binary_accuracy: 0.9073 - val_loss: 0.2425 - val_binary_accuracy: 0.8948\n",
      "Epoch 180/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2297 - binary_accuracy: 0.9078 - val_loss: 0.2428 - val_binary_accuracy: 0.8925\n",
      "Epoch 181/200\n",
      "237/237 [==============================] - 72s 306ms/step - loss: 0.2298 - binary_accuracy: 0.9078 - val_loss: 0.2422 - val_binary_accuracy: 0.8939\n",
      "Epoch 182/200\n",
      "237/237 [==============================] - 72s 306ms/step - loss: 0.2296 - binary_accuracy: 0.9081 - val_loss: 0.2418 - val_binary_accuracy: 0.8948\n",
      "Epoch 183/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2293 - binary_accuracy: 0.9081 - val_loss: 0.2418 - val_binary_accuracy: 0.8948\n",
      "Epoch 184/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2292 - binary_accuracy: 0.9079 - val_loss: 0.2420 - val_binary_accuracy: 0.8953\n",
      "Epoch 185/200\n",
      "237/237 [==============================] - 72s 303ms/step - loss: 0.2290 - binary_accuracy: 0.9081 - val_loss: 0.2418 - val_binary_accuracy: 0.8935\n",
      "Epoch 186/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2289 - binary_accuracy: 0.9081 - val_loss: 0.2414 - val_binary_accuracy: 0.8948\n",
      "Epoch 187/200\n",
      "237/237 [==============================] - 72s 305ms/step - loss: 0.2288 - binary_accuracy: 0.9084 - val_loss: 0.2417 - val_binary_accuracy: 0.8939\n",
      "Epoch 188/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2287 - binary_accuracy: 0.9088 - val_loss: 0.2413 - val_binary_accuracy: 0.8944\n",
      "Epoch 189/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2284 - binary_accuracy: 0.9092 - val_loss: 0.2417 - val_binary_accuracy: 0.8930\n",
      "Epoch 190/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2284 - binary_accuracy: 0.9085 - val_loss: 0.2414 - val_binary_accuracy: 0.8953\n",
      "Epoch 191/200\n",
      "237/237 [==============================] - 73s 306ms/step - loss: 0.2281 - binary_accuracy: 0.9087 - val_loss: 0.2411 - val_binary_accuracy: 0.8953\n",
      "Epoch 192/200\n",
      "237/237 [==============================] - 75s 318ms/step - loss: 0.2280 - binary_accuracy: 0.9084 - val_loss: 0.2413 - val_binary_accuracy: 0.8944\n",
      "Epoch 193/200\n",
      "237/237 [==============================] - 74s 313ms/step - loss: 0.2278 - binary_accuracy: 0.9091 - val_loss: 0.2412 - val_binary_accuracy: 0.8948\n",
      "Epoch 194/200\n",
      "237/237 [==============================] - 73s 309ms/step - loss: 0.2278 - binary_accuracy: 0.9089 - val_loss: 0.2410 - val_binary_accuracy: 0.8930\n",
      "Epoch 195/200\n",
      "237/237 [==============================] - 73s 307ms/step - loss: 0.2278 - binary_accuracy: 0.9096 - val_loss: 0.2413 - val_binary_accuracy: 0.8953\n",
      "Epoch 196/200\n",
      "237/237 [==============================] - 72s 304ms/step - loss: 0.2276 - binary_accuracy: 0.9088 - val_loss: 0.2411 - val_binary_accuracy: 0.8953\n",
      "Epoch 197/200\n",
      "237/237 [==============================] - 76s 321ms/step - loss: 0.2275 - binary_accuracy: 0.9091 - val_loss: 0.2410 - val_binary_accuracy: 0.8953\n",
      "Epoch 198/200\n",
      "237/237 [==============================] - 76s 321ms/step - loss: 0.2272 - binary_accuracy: 0.9087 - val_loss: 0.2407 - val_binary_accuracy: 0.8944\n",
      "Epoch 199/200\n",
      "237/237 [==============================] - 75s 318ms/step - loss: 0.2271 - binary_accuracy: 0.9094 - val_loss: 0.2406 - val_binary_accuracy: 0.8953\n",
      "Epoch 200/200\n",
      "237/237 [==============================] - 75s 317ms/step - loss: 0.2270 - binary_accuracy: 0.9094 - val_loss: 0.2412 - val_binary_accuracy: 0.8921\n"
     ]
    }
   ],
   "source": [
    "# Definir el callback de EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitorea la pérdida de validación\n",
    "    patience=20,         # Número de épocas sin mejoría para detener el entrenamiento\n",
    "    verbose=1,           # Mensajes de salida en el entrenamiento\n",
    "    restore_best_weights=True,\n",
    "    min_delta=0.001# Restaura los pesos del mejor modelo al final del entrenamiento\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con el callback de EarlyStopping\n",
    "history = model.fit(\n",
    "    train_gen,\n",
    "    epochs=200,\n",
    "    validation_data=val_gen,\n",
    "    callbacks=[early_stopping]  # Pasar el callback de EarlyStopping\n",
    ")\n",
    "\n",
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.to_csv(f\"labels/{carpetas[2]}/history_trasfer.csv\",index=False)\n",
    "model.save_weights(f'labels/{carpetas[2]}/checkpoints_transfer/my_checkpoint_transfer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "432a37d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
